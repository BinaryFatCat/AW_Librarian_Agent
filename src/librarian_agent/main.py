"""
CLI å…¥å£æ¨¡å—
æä¾›å‘½ä»¤è¡Œäº¤äº’ç•Œé¢ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ‰§è¡Œ
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from typing import List

from langchain_openai import ChatOpenAI

from .graph import create_librarian_graph
from .state import LibrarianState


def print_banner():
    """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
    print("\n" + "=" * 60)
    print("  ğŸ“š The Librarian Agent - çŸ¥è¯†åº“ä¸“å®¶")
    print("  åŸºäº LangGraph æ¡†æ¶ | æ”¯æŒ DeepSeek R1/V3")
    print("=" * 60)


def get_user_config():
    """äº¤äº’å¼è·å–ç”¨æˆ·é…ç½®"""
    print("\nğŸ“‹ è¯·é…ç½®ä»¥ä¸‹å‚æ•°:\n")
    
    # API é…ç½®
    api_key = input("ğŸ”‘ API Key: ").strip()
    if not api_key:
        print("âŒ API Key ä¸èƒ½ä¸ºç©º!")
        sys.exit(1)
    
    base_url = input("ğŸŒ Base URL (å›è½¦ä½¿ç”¨é»˜è®¤ https://dashscope.aliyuncs.com/compatible-mode/v1): ").strip()
    if not base_url:
        base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    
    model_name = input("ğŸ¤– æ¨¡å‹åç§° (å›è½¦ä½¿ç”¨é»˜è®¤ deepseek-r1): ").strip()
    if not model_name:
        model_name = "deepseek-r1"
    
    # è·¯å¾„é…ç½®
    print("\nğŸ“‚ è·¯å¾„é…ç½®:")
    lib_path = input("   AW åº“è·¯å¾„ (Markdown æ–‡ä»¶æ‰€åœ¨ç›®å½•): ").strip()
    if not lib_path or not os.path.isdir(lib_path):
        print(f"âŒ AW åº“è·¯å¾„æ— æ•ˆ: {lib_path}")
        sys.exit(1)
    
    input_json = input("   Parser è¾“å‡ºçš„ JSON æ–‡ä»¶è·¯å¾„: ").strip()
    if not input_json or not os.path.isfile(input_json):
        print(f"âŒ JSON æ–‡ä»¶ä¸å­˜åœ¨: {input_json}")
        sys.exit(1)
    
    output_path = input("   è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å›è½¦ä½¿ç”¨é»˜è®¤ librarian_output.json): ").strip()
    if not output_path:
        output_path = "librarian_output.json"
    
    return {
        "api_key": api_key,
        "base_url": base_url,
        "model_name": model_name,
        "library_path": os.path.abspath(lib_path),
        "input_json": input_json,
        "output_path": output_path,
    }


def load_parser_output(file_path: str) -> dict:
    """åŠ è½½ Parser Agent çš„è¾“å‡º JSON"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_all_steps(parser_data: dict) -> list:
    """ä» BDD ç»“æ„ä¸­æå–æ‰€æœ‰æ­¥éª¤"""
    flow = parser_data.get("bdd_flow", {})
    steps = []
    
    for phase in ["given", "when", "then", "cleanup"]:
        phase_steps = flow.get(phase, [])
        for step in phase_steps:
            step["phase"] = phase  # æ·»åŠ é˜¶æ®µæ ‡è¯†
            steps.append(step)
    
    return steps


def run_librarian(config: dict):
    """è¿è¡Œ Librarian Agentï¼ˆåŒæ­¥æ¨¡å¼ï¼‰"""
    
    # åˆå§‹åŒ– LLM
    print(f"\nğŸ”§ æ­£åœ¨åˆå§‹åŒ– LLM ({config['model_name']})...")
    model = ChatOpenAI(
        model=config["model_name"],
        openai_api_key=config["api_key"],
        openai_api_base=config["base_url"],
        temperature=0,
        max_tokens=4096,
    )
    
    # åˆ›å»º Graphï¼ˆä¼ å…¥ library_pathï¼‰
    print("ğŸ”§ æ­£åœ¨æ„å»º LangGraph å·¥ä½œæµ...")
    app = create_librarian_graph(model, config["library_path"])
    
    # åŠ è½½è¾“å…¥æ•°æ®
    print(f"ğŸ“„ æ­£åœ¨åŠ è½½: {config['input_json']}")
    parser_data = load_parser_output(config["input_json"])
    all_steps = extract_all_steps(parser_data)
    
    print(f"\nğŸ“Š å…±å‘ç° {len(all_steps)} ä¸ªæ­¥éª¤éœ€è¦åŒ¹é… AW")
    print("-" * 50)
    
    # å¤„ç†æ¯ä¸ªæ­¥éª¤
    all_results = []
    
    for i, step in enumerate(all_steps, 1):
        step_id = step.get("step_id", f"S{i}")
        description = step.get("description", "æœªçŸ¥æè¿°")
        phase = step.get("phase", "unknown")
        
        print(f"\nğŸ” [{i}/{len(all_steps)}] æ­£åœ¨å¤„ç†æ­¥éª¤ {step_id} ({phase})")
        print(f"   ğŸ“ {description}")
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state: LibrarianState = {
            "intent": parser_data,  # å®Œæ•´çš„ Parser è¾“å‡º
            "messages": [],
            "candidates": [],
            "result": {},
            "library_path": config["library_path"],
            "current_step": step,
            "debug": config.get("debug", False),  # ä¼ é€’è°ƒè¯•æ ‡å¿—
        }
        
        try:
            # è¿è¡Œ Agentï¼ˆåŒæ­¥ï¼‰
            final_state = app.invoke(initial_state)
            
            candidates = final_state.get("candidates", [])
            print(f"   âœ… æ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰ AW")
            
            for j, c in enumerate(candidates, 1):
                aw_id = c.get("aw_id", c.get("aw_name", "æœªçŸ¥"))
                reason = c.get("reason", "")[:50]
                print(f"      {j}. {aw_id}")
                if reason:
                    print(f"         â””â”€ {reason}...")
            
            all_results.append({
                "step_id": step_id,
                "phase": phase,
                "description": description,
                "action_type": step.get("action_type", step.get("check_type", "")),
                "candidates": candidates,
            })
            
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {str(e)}")
            all_results.append({
                "step_id": step_id,
                "phase": phase,
                "description": description,
                "error": str(e),
                "candidates": [],
            })
    
    return _save_results(config, parser_data, all_results)


async def run_librarian_async(config: dict):
    """
    è¿è¡Œ Librarian Agentï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰
    ä½¿ç”¨ LangGraph çš„ ainvoke å®ç°å¼‚æ­¥æ‰§è¡Œ
    """
    
    # åˆå§‹åŒ– LLM
    print(f"\nğŸ”§ æ­£åœ¨åˆå§‹åŒ– LLM ({config['model_name']})... [å¼‚æ­¥æ¨¡å¼]")
    model = ChatOpenAI(
        model=config["model_name"],
        openai_api_key=config["api_key"],
        openai_api_base=config["base_url"],
        temperature=0,
        max_tokens=4096,
    )
    
    # åˆ›å»º Graphï¼ˆä¼ å…¥ library_pathï¼‰
    print("ğŸ”§ æ­£åœ¨æ„å»º LangGraph å·¥ä½œæµ...")
    app = create_librarian_graph(model, config["library_path"])
    
    # åŠ è½½è¾“å…¥æ•°æ®
    print(f"ğŸ“„ æ­£åœ¨åŠ è½½: {config['input_json']}")
    parser_data = load_parser_output(config["input_json"])
    all_steps = extract_all_steps(parser_data)
    
    print(f"\nğŸ“Š å…±å‘ç° {len(all_steps)} ä¸ªæ­¥éª¤éœ€è¦åŒ¹é… AW")
    print("-" * 50)
    
    # å¼‚æ­¥å¤„ç†æ¯ä¸ªæ­¥éª¤
    all_results = []
    
    async def process_step(i: int, step: dict) -> dict:
        """å¼‚æ­¥å¤„ç†å•ä¸ªæ­¥éª¤"""
        step_id = step.get("step_id", f"S{i}")
        description = step.get("description", "æœªçŸ¥æè¿°")
        phase = step.get("phase", "unknown")
        
        print(f"\nğŸ” [{i}/{len(all_steps)}] æ­£åœ¨å¤„ç†æ­¥éª¤ {step_id} ({phase})")
        print(f"   ğŸ“ {description}")
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state: LibrarianState = {
            "intent": parser_data,
            "messages": [],
            "candidates": [],
            "result": {},
            "library_path": config["library_path"],
            "current_step": step,
            "debug": config.get("debug", False),  # ä¼ é€’è°ƒè¯•æ ‡å¿—
        }
        
        try:
            # ä½¿ç”¨ ainvoke å¼‚æ­¥è¿è¡Œ Agent
            final_state = await app.ainvoke(initial_state)
            
            candidates = final_state.get("candidates", [])
            print(f"   âœ… æ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰ AW")
            
            for j, c in enumerate(candidates, 1):
                aw_id = c.get("aw_id", c.get("aw_name", "æœªçŸ¥"))
                reason = c.get("reason", "")[:50]
                print(f"      {j}. {aw_id}")
                if reason:
                    print(f"         â””â”€ {reason}...")
            
            return {
                "step_id": step_id,
                "phase": phase,
                "description": description,
                "action_type": step.get("action_type", step.get("check_type", "")),
                "candidates": candidates,
            }
            
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {str(e)}")
            return {
                "step_id": step_id,
                "phase": phase,
                "description": description,
                "error": str(e),
                "candidates": [],
            }
    
    # é¡ºåºå¼‚æ­¥æ‰§è¡Œï¼ˆä¿æŒè¾“å‡ºé¡ºåºï¼‰
    for i, step in enumerate(all_steps, 1):
        result = await process_step(i, step)
        all_results.append(result)
    
    return _save_results(config, parser_data, all_results)


def _save_results(config: dict, parser_data: dict, all_results: List[dict]) -> dict:
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    output_payload = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "model": config["model_name"],
            "library_path": config["library_path"],
        },
        "scenario_metadata": parser_data.get("scenario_metadata", {}),
        "librarian_output": all_results,
    }
    
    # ä¿å­˜ç»“æœ
    with open(config["output_path"], 'w', encoding='utf-8') as f:
        json.dump(output_payload, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 50)
    print(f"âœ… å¤„ç†å®Œæˆ! ç»“æœå·²ä¿å­˜è‡³: {config['output_path']}")
    print("=" * 50)
    
    return output_payload


def main():
    """ä¸»å…¥å£å‡½æ•°ï¼ˆæ”¯æŒåŒæ­¥/å¼‚æ­¥æ¨¡å¼é€‰æ‹©ï¼‰"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="Librarian Agent - çŸ¥è¯†åº“ä¸“å®¶")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„ LLM å’Œå·¥å…·è°ƒç”¨ä¿¡æ¯")
    parser.add_argument("--intent", type=str, help="Parser è¾“å‡ºçš„ JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--library", type=str, help="AW åº“è·¯å¾„ (Markdown æ–‡ä»¶æ‰€åœ¨ç›®å½•)")
    parser.add_argument("--output", type=str, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--async", dest="use_async", action="store_true", help="ä½¿ç”¨å¼‚æ­¥æ¨¡å¼")
    args = parser.parse_args()
    
    print_banner()
    
    try:
        # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
        if args.intent and args.library:
            if not os.path.isfile(args.intent):
                print(f"âŒ JSON æ–‡ä»¶ä¸å­˜åœ¨: {args.intent}")
                sys.exit(1)
            if not os.path.isdir(args.library):
                print(f"âŒ AW åº“è·¯å¾„æ— æ•ˆ: {args.library}")
                sys.exit(1)
            
            # ä»ç¯å¢ƒå˜é‡è·å– API é…ç½®
            api_key = os.environ.get("OPENAI_API_KEY", os.environ.get("DASHSCOPE_API_KEY", ""))
            if not api_key:
                print("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ– DASHSCOPE_API_KEY")
                sys.exit(1)
            
            config = {
                "api_key": api_key,
                "base_url": os.environ.get("OPENAI_API_BASE", "https://dashscope.aliyuncs.com/compatible-mode/v1"),
                "model_name": os.environ.get("MODEL_NAME", "deepseek-r1"),
                "library_path": os.path.abspath(args.library),
                "input_json": args.intent,
                "output_path": args.output or "librarian_output.json",
                "debug": args.debug,
            }
            
            print(f"ğŸ“‚ AW åº“: {config['library_path']}")
            print(f"ğŸ“„ Intent: {config['input_json']}")
            print(f"ğŸ¤– æ¨¡å‹: {config['model_name']}")
        else:
            # äº¤äº’æ¨¡å¼
            config = get_user_config()
            config["debug"] = args.debug
        
        if args.debug:
            print("\nğŸ” [è°ƒè¯•æ¨¡å¼å·²å¯ç”¨] - å°†æ˜¾ç¤ºè¯¦ç»†çš„æ¨ç†å’Œå·¥å…·è°ƒç”¨è¿‡ç¨‹")
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
        if args.intent and args.library:
            use_async = args.use_async
        else:
            use_async = input("\nğŸ”„ æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼? (y/N): ").strip().lower() == 'y'
        
        if use_async:
            print("ğŸ“¡ å¯ç”¨å¼‚æ­¥æ¨¡å¼...")
            asyncio.run(run_librarian_async(config))
        else:
            print("ğŸ“¡ ä½¿ç”¨åŒæ­¥æ¨¡å¼...")
            run_librarian(config)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
